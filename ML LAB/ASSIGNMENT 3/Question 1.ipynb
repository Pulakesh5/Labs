{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training & Testing daatsets using given mean and covariance metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "N = 1000\n",
    "prior_probabilities = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Mean vectors\n",
    "m1 = np.array([0, 0, 0])\n",
    "m2 = np.array([1, 2, 2])\n",
    "m3 = np.array([3, 3, 4])\n",
    "\n",
    "# Covariance matrices\n",
    "S1 = np.array([[0.8, 0.2, 0.1],\n",
    "               [0.2, 0.8, 0.2],\n",
    "               [0.1, 0.2, 0.8]])\n",
    "\n",
    "S2 = np.array([[0.6, 0.01, 0.01],\n",
    "               [0.01, 0.8, 0.01],\n",
    "               [0.01, 0.01, 0.6]])\n",
    "\n",
    "S3 = np.array([[0.6, 0.1, 0.1],\n",
    "               [0.1, 0.6, 0.1],\n",
    "               [0.1, 0.1, 0.6]])\n",
    "\n",
    "# Generate datasets\n",
    "X = []\n",
    "X1 = []\n",
    "for _ in range(N):\n",
    "    # Randomly select a class based on prior probabilities\n",
    "    class_idx = np.random.choice([0, 1, 2], p=prior_probabilities)\n",
    "    \n",
    "    # Generate data point based on selected class\n",
    "    if class_idx == 0:\n",
    "        x = np.random.multivariate_normal(m1, S1)\n",
    "    elif class_idx == 1:\n",
    "        x = np.random.multivariate_normal(m2, S2)\n",
    "    else:\n",
    "        x = np.random.multivariate_normal(m3, S3)\n",
    "    \n",
    "    # Add data point to the dataset\n",
    "    X.append(x)\n",
    "\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "# Generate test set X1 in the same way\n",
    "# Assign true class labels to the test set based on how it was generated\n",
    "for _ in range(N):\n",
    "    class_idx = np.random.choice([0, 1, 2], p=prior_probabilities)\n",
    "    \n",
    "    if class_idx == 0:\n",
    "        x = np.random.multivariate_normal(m1, S1)\n",
    "        true_labels.append(\"w1\")\n",
    "    elif class_idx == 1:\n",
    "        x = np.random.multivariate_normal(m2, S2)\n",
    "        true_labels.append(\"w2\")\n",
    "    else:\n",
    "        x = np.random.multivariate_normal(m3, S3)\n",
    "        true_labels.append(\"w3\")\n",
    "    \n",
    "    X1.append(x)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "\n",
    "# Save the datasets if needed\n",
    "np.save('X.npy', X)\n",
    "np.save('X1.npy', X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Using Euclidean distance classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X1 = np.load('X1.npy') # Test set\n",
    "# Mean vectors for the classes\n",
    "m1 = np.array([0, 0, 0])\n",
    "m2 = np.array([1, 2, 2])\n",
    "m3 = np.array([3, 3, 4])\n",
    "# Initialize an array to store the predicted class labels\n",
    "predicted_labels = []\n",
    "# Classify each point in X1\n",
    "for x in X1:\n",
    "    # Calculate Euclidean distances to each class mean\n",
    "    dist_to_m1 = np.linalg.norm(x - m1)\n",
    "    dist_to_m2 = np.linalg.norm(x - m2)\n",
    "    dist_to_m3 = np.linalg.norm(x - m3)\n",
    "    \n",
    "    # Find the class with the minimum distance\n",
    "    min_distance = min(dist_to_m1, dist_to_m2, dist_to_m3)\n",
    "    \n",
    "    # Assign the predicted class label based on the minimum distance\n",
    "    if min_distance == dist_to_m1:\n",
    "        predicted_labels.append(\"w1\")\n",
    "    elif min_distance == dist_to_m2:\n",
    "        predicted_labels.append(\"w2\")\n",
    "    else:\n",
    "        predicted_labels.append(\"w3\")\n",
    "# Print the predicted labels for the test set\n",
    "# for i, label in enumerate(predicted_labels):\n",
    "#     print(f\"Point {i+1}: Predicted class = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Using Mahalanobis distance classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X1 = np.load('X1.npy') # Test set\n",
    "\n",
    "# Mean vectors for the classes\n",
    "m1 = np.array([0, 0, 0])\n",
    "m2 = np.array([1, 2, 2])\n",
    "m3 = np.array([3, 3, 4])\n",
    "\n",
    "# Covariance matrices for the classes\n",
    "S1 = np.array([[0.8, 0.2, 0.1],\n",
    "               [0.2, 0.8, 0.2],\n",
    "               [0.1, 0.2, 0.8]])\n",
    "\n",
    "S2 = np.array([[0.6, 0.01, 0.01],\n",
    "               [0.01, 0.8, 0.01],\n",
    "               [0.01, 0.01, 0.6]])\n",
    "\n",
    "S3 = np.array([[0.6, 0.1, 0.1],\n",
    "               [0.1, 0.6, 0.1],\n",
    "               [0.1, 0.1, 0.6]])\n",
    "\n",
    "S1_inv = np.linalg.inv(S1)\n",
    "S2_inv = np.linalg.inv(S2)\n",
    "S3_inv = np.linalg.inv(S3)\n",
    "# Initialize an array to store the predicted class labels\n",
    "predicted_labels_mnb = []\n",
    "\n",
    "# Classify each point in X1 using Mahalanobis distance\n",
    "for x in X1:\n",
    "    # Calculate Mahalanobis distances to each class mean\n",
    "#     mnb_dist_m1 = np.sqrt((x - m1).T @ S1_inv @ (x - m1))\n",
    "#     mnb_dist_m2 = np.sqrt((x - m2).T @ S2_inv @ (x - m2))\n",
    "#     mnb_dist_m3 = np.sqrt((x - m3).T @ S3_inv @ (x - m3))\n",
    "\n",
    "    mnb_dist_m1 = np.sqrt(np.dot(np.dot((x - m1).T , S1_inv), (x - m1)))\n",
    "    mnb_dist_m2 = np.sqrt(np.dot(np.dot((x - m2).T , S2_inv), (x - m2)))\n",
    "    mnb_dist_m3 = np.sqrt(np.dot(np.dot((x - m3).T , S3_inv), (x - m3)))\n",
    "    \n",
    "    # Find the class with the minimum Mahalanobis distance\n",
    "    min_mahalanobis_dist = min(mnb_dist_m1, mnb_dist_m2, mnb_dist_m3)\n",
    "    \n",
    "    # Assign the predicted class label based on the minimum Mahalanobis distance\n",
    "    if min_mahalanobis_dist == mnb_dist_m1:\n",
    "        predicted_labels_mnb.append(\"w1\")\n",
    "    elif min_mahalanobis_dist == mnb_dist_m2:\n",
    "        predicted_labels_mnb.append(\"w2\")\n",
    "    else:\n",
    "        predicted_labels_mnb.append(\"w3\")\n",
    "\n",
    "# Print the predicted labels for the test set using Mahalanobis distance\n",
    "# for i, label in enumerate(predicted_labels_mnb):\n",
    "#     print(f\"Point {i+1}): Predicted class = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify using Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "# Load the datasets\n",
    "X1 = np.load('X1.npy') # Test set\n",
    "\n",
    "# Mean vectors for the classes\n",
    "m1 = np.array([0, 0, 0])\n",
    "m2 = np.array([1, 2, 2])\n",
    "m3 = np.array([3, 3, 4])\n",
    "\n",
    "# Covariance matrices for the classes\n",
    "S1 = np.array([[0.8, 0.2, 0.1],\n",
    "               [0.2, 0.8, 0.2],\n",
    "               [0.1, 0.2, 0.8]])\n",
    "\n",
    "S2 = np.array([[0.6, 0.01, 0.01],\n",
    "               [0.01, 0.8, 0.01],\n",
    "               [0.01, 0.01, 0.6]])\n",
    "\n",
    "S3 = np.array([[0.6, 0.1, 0.1],\n",
    "               [0.1, 0.6, 0.1],\n",
    "               [0.1, 0.1, 0.6]])\n",
    "\n",
    "# Prior probabilities for the classes\n",
    "prior_probabilities = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Initialize an array to store the predicted class labels\n",
    "predicted_labels_bayesian = []\n",
    "\n",
    "# Classify each point in X1 using Bayesian classifier\n",
    "for x in X1:\n",
    "    # Calculate class-conditional densities using multivariate normal distribution\n",
    "    p_x_given_m1 = multivariate_normal.pdf(x, mean=m1, cov=S1)\n",
    "    p_x_given_m2 = multivariate_normal.pdf(x, mean=m2, cov=S2)\n",
    "    p_x_given_m3 = multivariate_normal.pdf(x, mean=m3, cov=S3)\n",
    "    \n",
    "    # Calculate posterior probabilities using Bayes' theorem\n",
    "    posterior_m1 = p_x_given_m1 * prior_probabilities[0]\n",
    "    posterior_m2 = p_x_given_m2 * prior_probabilities[1]\n",
    "    posterior_m3 = p_x_given_m3 * prior_probabilities[2]\n",
    "    \n",
    "    # Find the class with the maximum posterior probability\n",
    "    max_posterior = max(posterior_m1, posterior_m2, posterior_m3)\n",
    "    \n",
    "    # Assign the predicted class label based on the maximum posterior probability\n",
    "    if max_posterior == posterior_m1:\n",
    "        predicted_labels_bayesian.append(\"w1\")\n",
    "    elif max_posterior == posterior_m2:\n",
    "        predicted_labels_bayesian.append(\"w2\")\n",
    "    else:\n",
    "        predicted_labels_bayesian.append(\"w3\")\n",
    "\n",
    "# Print the predicted labels for the test set using the Bayesian classifier\n",
    "# for i, label in enumerate(predicted_labels_bayesian):\n",
    "#     print(f\"Point {i+1}: Predicted class = {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each class, compute the error probability and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Probability (Euclidean Distance Classifier): 7.00\n",
      "Error Probability (Mahalanobis Distance Classifier): 6.30\n",
      "Error Probability (Bayesian Classifier): 6.60%\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "X1 = np.load('X1.npy') # Test set\n",
    "\n",
    "# Function to calculate error probability\n",
    "def calculate_error_prob(true_labels, predicted_labels):\n",
    "    incorrect_count = 0\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        if true_label != predicted_label:\n",
    "            incorrect_count += 1\n",
    "    error_prob = incorrect_count / len(true_labels)\n",
    "    return error_prob\n",
    "\n",
    "# Calculate error probabilities for each classifier\n",
    "error_prob_euclidean = calculate_error_prob(true_labels, predicted_labels)\n",
    "error_prob_mnb = calculate_error_prob(true_labels, predicted_labels_mnb)\n",
    "error_prob_bayesian = calculate_error_prob(true_labels, predicted_labels_bayesian)\n",
    "\n",
    "# Print the error probabilities for each classifier\n",
    "print(f\"Error Probability (Euclidean Distance Classifier): {error_prob_euclidean*100:.2f}\")\n",
    "print(f\"Error Probability (Mahalanobis Distance Classifier): {error_prob_mnb*100:.2f}\")\n",
    "print(f\"Error Probability (Bayesian Classifier): {error_prob_bayesian*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
